## 手法
VGG16もモデルを利用しました。16層からなるモデルですが、14層までを凍結して、15〜16層の全結合層のみを学習しました。

## 画像データ収集
Googleから画像を一括でダウンロードできるコマンドラインツール「google-images-download」を利用しました。
参考にしたサイト：https://co.bsnws.net/article/295
```
pip install google_images_download
```
**データセット割合**
１作者あたり
　訓練データ：300枚
　検証データ：100枚
　テストデータ：35枚
5作者分用意したので、訓練データは1,500枚用意しました。

### 苦労した点
**googleimagesdownloadの手法に行き着くのに時間が掛かった**
　・最初はBing Seach APIを使っていた。
　・googleimagesdownloadのデフォルトは100枚までしかダウンロード出来ないが、-cdのオプションを追加することで、100枚以上のデータのダウンロードができるようになった。
**画像データセットの準備に苦労した**
　・削除するデータ
　　　・重複画像データ
　　　・できる限り作者の名前が入ったデータ
　　　・作者以外の人が書いたデータ
　　　・作者本人の顔写真
　　　・キャラクターグッズのデータ
　・100枚の中から数枚しか使えるデータが無い場合もあるため、検索文字が大事
　　　例）「ドラゴンボール」ではなく「天津飯　ドラゴンボール」などキャラクター名を指定した方が良質なデータが集まる気がする
以下のようなコマンドでデータを落としてきました。

```
googleimagesdownload -k "ジャイアン　のび太" -l 500 -cd "/Users/XXXX/Downloads/chromedriver"
```

### 工夫した点
**データセットの件数はそのままで少し中身を入れ替えた**
修正前のデータセットは、コミックのデータセットも多く含まれています。
修正後のデータセットからは、コミックのデータセットを削減して、キャラクター画像に置き換えました。
その結果、オプティマイザ「Adam」を利用して、epochs:70で回した結果、accuracyが2ポイントほど上がりました。

## 実装
スクリプト、データセットはGitHubに置いてます。[GitHub](https://github.com/ttomomasa/diveintocode-term3)
