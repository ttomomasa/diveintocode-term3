
# å…±åŒèª²é¡Œ
ãƒ¡ãƒ³ãƒãƒ¼ï¼šå®‰è—¤ã€çœé‡ã€çªªç”°ã€ï¼ˆä½è—¤ï¼‰ã€å‹æ­£  
å®Ÿæ–½æ—¥ç¨‹ï¼š2019å¹´1æœˆ12ï¼ˆåœŸï¼‰ã€œ18ï¼ˆé‡‘ï¼‰

# ç›®çš„
## MVP(Minimum Viable Product)ã‚’ä½œã£ã¦ã¿ã‚‹  
â— ã€Œå®Ÿç”¨æœ€ä½é™ã®è£½å“ã€ã¨è¨³ã•ã‚Œã‚‹  
â— ä»®èª¬ãŒæ­£ã—ã„ã‹é¡§å®¢ã‹ã‚‰ã®åå¿œã‚’å¾—ã‚‹ãŸã‚ã«ä½¿ã†   
â— ãƒãƒ¼ãƒ ã§æŠ€è¡“çš„ã«å¯èƒ½ã‹ã®æ¤œè¨¼ã¨ã„ã†é¢ã‚‚ã‚ã‚‹  
â— è²»ç”¨ã‚’ã‹ã‘ãšçŸ­æœŸé–“ã§MVPã‚’ä½œã‚Šã€æ¤œè¨¼ã‚’ç¹°ã‚Šè¿”ã™  

## é€²ã‚æ–¹
â— ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºã®ä¸€é€£ã®æµã‚Œã‚’ä½“é¨“ã™ã‚‹  
â— ãƒãƒ¼ãƒ ã§é–‹ç™ºã‚’è¡Œã†  
â— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹  

# èª²é¡Œ
ã€Œç„¡äººãƒ¬ã‚¸ã€ã®é–‹ç™ºã‚’æŒã¡ã‹ã‘ã‚‰ã‚ŒãŸã¨æƒ³å®šã—ã€ãƒãƒ¼ãƒ ã§MVP ã‚’ä½œæˆã™ã‚‹ã€‚2æ—¥æ¯ã«ä¸­é–“ç™ºè¡¨ã€æ¥é€±åœŸæ›œæ—¥æœï¼ˆ1/19ï¼ˆåœŸï¼‰ï¼‰ã«ã¯ãƒ—ãƒ­ãƒ€ ã‚¯ãƒˆã®å®Ÿæ¼”ã‚’çµ¡ã‚ãŸæœ€çµ‚ç™ºè¡¨ã‚’è¡Œã†ã€‚

# èª²é¡Œå®šç¾©
ä»¥ä¸‹ã®5éŠ˜æŸ„ã®ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ã‚’ãƒ©ã‚ºãƒ‘ã‚¤ã®ã‚«ãƒ¡ãƒ©ã§èªè­˜ã—ã¦ã€ãã®éŠ˜æŸ„ã‚’æ­£ã—ãèªè­˜ã™ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¨ã™ã‚‹ã€‚  
ã“ã®éŠ˜æŸ„ã‚’é¸ã‚“ã ç†ç”±ã¯ã€ä¸€èˆ¬çš„ã«çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹éŠ˜æŸ„ã§ã‚ã‚‹ã“ã¨ã¨ã€1çµ„ã¯ä¼¼ãŸéŠ˜æŸ„ã‚’å«ã‚ã‚‹ã“ã¨ï¼ˆã€Œãã¡ã©ã‘ã‚‚ã‚‚ã€ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€ï¼‰ã€‚

â— ã€Œã„ã‚ã¯ã™ã€æ—¥æœ¬ã‚³ã‚«ã‚³ãƒ¼ãƒ©ã€€555ml  
â— ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€æ—¥æœ¬ã‚³ã‚«ã‚³ãƒ¼ãƒ©ã€€500ml  
â— ã€ŒãŠã€œã„ãŠèŒ¶ã€ä¼Šè—¤åœ’ã€€600ml  
â— ã€Œãã¡ã©ã‘ã‚‚ã‚‚ã€ä¸‰ãƒ„çŸ¢ã‚µã‚¤ãƒ€ãƒ¼ã€€500ml  
â— ã€Œãƒã‚«ãƒªã‚¹ã‚¨ãƒƒãƒˆã€å¤§å¡šè£½è–¬ 500ml  
![5.JPG](attachment:5.JPG)

## å‰æ
5ç¨®é¡ã®éŠ˜æŸ„ä»¥å¤–ã«è¿½åŠ ã™ã‚‹å ´åˆã¯ã€ä»Šã®ã¨ã“ã‚ã‚‚ã†ä¸€åº¦å­¦ç¿’ã—ç›´ã—ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã€‚ãƒãƒƒãƒå­¦ç¿’ãŒå‰æã¨ã—ã¦ã„ã¾ã™ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãŒã§ãã‚Œã°ç†æƒ³ã ã¨æ€ã„ã¾ã™ãŒä»Šå›ã¯æ¤œè¨å¯¾è±¡å¤–ã¨ã—ã¾ã—ãŸã€‚

## åˆ©ç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸
ãƒ©ã‚ºãƒ‘ã‚¤ã®ã‚«ãƒ¡ãƒ©ã‚’ã‚»ãƒ«ãƒ•ãƒ¬ã‚¸ã¨æƒ³å®šã™ã‚‹ã€‚ä»¥ä¸‹ã®æ‰‹é †ã®é‹ç”¨ã‚’æƒ³å®šã™ã‚‹ã€‚

â‘ ãã®ã‚«ãƒ¡ãƒ©ã‹ã‚‰å®šç‚¹ã®ä½ç½®ã«5ç¨®é¡ã®ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ã‚’ç½®ã  
â‘¡èªè­˜é–‹å§‹ã®ãƒˆãƒªã‚¬ãƒ¼ã¯ã€ãƒ©ã‚ºãƒ‘ã‚¤ã‹ã‚‰ç¹‹ãŒã£ã¦ã„ã‚‹ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚­ãƒ¼ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹  
â‘¢ãƒ©ã‚ºãƒ‘ã‚¤ãŒèªè­˜ã—ãŸã‚‰ãƒ“ãƒ¼ãƒ—éŸ³ãŒé³´ã‚Šã€ãƒ©ã‚ºãƒ‘ã‚¤ã‹ã‚‰ç¹‹ãŒã£ã¦ã„ã‚‹ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«5éŠ˜æŸ„ã®ã„ãšã‚Œã‹ãŒè¡¨ç¤ºã•ã‚Œã‚‹  

## å½¹å‰²åˆ†æ‹…
å®‰è—¤ï¼šèª¿æŸ»æ¤œè¨ï¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ  
çœé‡ï¼šèª¿æŸ»æ¤œè¨ï¼ãƒ©ã‚ºãƒ‘ã‚¤å®Ÿè£…ï¼ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼  
çªªç”°ï¼šèª¿æŸ»æ¤œè¨ï¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ  
å‹æ­£ï¼šèª¿æŸ»æ¤œè¨ï¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ãƒ¢ãƒ‡ãƒ«å®Ÿè£…  

# ä½œæ¥­ã‚¹ãƒ†ãƒƒãƒ—
â‘ ãƒšãƒƒãƒˆãƒœãƒˆãƒ«è³¼å…¥ï¼å·¥å…·è³¼å…¥ã€‚æ¸‹è°·ãƒãƒ¼ã‚¯ã‚·ãƒ†ã‚£ã®familymartã®ã‚»ãƒ«ãƒ•ãƒ¬ã‚¸ã§å®Ÿéš›ã«è³¼å…¥ã‚’è¡Œã„ã€æŒ™å‹•ã‚’ç¢ºèªã€‚ã€€1/12ï¼ˆåœŸï¼‰  
![conv.JPG](attachment:conv.JPG)
â‘¡ãƒ©ã‚ºãƒ‘ã‚¤æº–å‚™ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€€1/12ï¼ˆåœŸï¼‰  
![IMG_0638.jpeg](attachment:IMG_0638.jpeg)
â‘¢ãƒ‡ãƒ¼ã‚¿ä½œæˆã€€1/13ï¼ˆæ—¥ï¼‰ã€16ï¼ˆæ°´ï¼‰ã€17ï¼ˆæœ¨ï¼‰  

â‘£éŸ³å£°çµ„ã¿è¾¼ã¿ï¼ãƒ©ã‚ºãƒ‘ã‚¤ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ä½œæˆã€€1/13ï¼ˆæ—¥ï¼‰  

â‘¤å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆãƒ»æ¤œè¨¼ã€€1/14ï¼ˆæœˆï¼‰ï½18ï¼ˆé‡‘ï¼‰  

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿

ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã€‚  
**ï¼œ1å•†å“ã‚ãŸã‚Šï¼**  
è¨“ç·´ãƒ‡ãƒ¼ã‚¿    ï¼š 3,000æšï¼ˆå†…è¨³ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿2,400æšã€ã‚­ãƒƒãƒãƒªãƒ‡ãƒ¼ã‚¿600æšï¼‰  
æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿    ï¼š 1,250æšï¼ˆå†…è¨³ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿1,000æšã€ã‚­ãƒƒãƒãƒªãƒ‡ãƒ¼ã‚¿250æšï¼‰  
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿1 ï¼š 87æšï¼ˆã‚­ãƒƒãƒãƒªï¼‰  
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿2 ï¼š 68æšï¼ˆãƒãƒ©ãƒãƒ©ï¼‰  
åˆè¨ˆï¼š4,337æš  

**ï¼œ5å•†å“ï¼**  
è¨“ç·´ãƒ‡ãƒ¼ã‚¿    ï¼š 15,000æšï¼ˆå†…è¨³ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿12,000æšã€ã‚­ãƒƒãƒãƒªãƒ‡ãƒ¼ã‚¿3,000æšï¼‰   
æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿    ï¼š 6,250æšï¼ˆå†…è¨³ï¼šãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿5,000æšã€ã‚­ãƒƒãƒãƒªãƒ‡ãƒ¼ã‚¿1,250æšï¼‰   
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿1 ï¼š 435æšï¼ˆã‚­ãƒƒãƒãƒªï¼‰  
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿2 ï¼š 340æšï¼ˆãƒãƒ©ãƒãƒ©ï¼‰  
åˆè¨ˆï¼š22,025æš  

**ï¼œä½œæˆæ–¹æ³•ï¼**  
**ã‚­ãƒƒãƒãƒªãƒ‡ãƒ¼ã‚¿**  
ãƒ»ç™½ãƒœãƒƒã‚¯ã‚¹ã‚’ç”¨æ„ã—ã¦ã€1å•†å“å½“ãŸã‚Š30åˆ†æ›ã‘ã¦æ‰‹å‹•ã§å›è»¢ã•ã›ã¦å‹•ç”»ã‚’ä½œæˆã—ã¦ã€ãã®å‹•ç”»ã‹ã‚‰é™æ­¢ç”»ã‚’ä½œæˆï¼ˆå‹•ç”»å‚ç…§ï¼‰ã€‚     
ãƒ»åˆ©ç”¨ã—ãŸãƒ„ãƒ¼ãƒ«ï¼šVLCãƒ„ãƒ¼ãƒ«ï¼ˆå‹•ç”»å†ç”Ÿï¼‰  
å‚è€ƒã«ã—ãŸã‚µã‚¤ãƒˆï¼šhttp://blog.hieroglyph.me/archives/49  
![kicchiri.JPG](attachment:kicchiri.JPG)


**ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿**  
æ§˜ã€…ãªè§’åº¦ã‹ã‚‰å•†å“ã‚’å‹•ç”»ã§ä½œæˆã€‚ãã®å‹•ç”»ã‹ã‚‰é™æ­¢ç”»ã‚’ä½œæˆã€‚  
åˆ©ç”¨ã—ãŸãƒ„ãƒ¼ãƒ«ï¼šGOM Player
å‚è€ƒã«ã—ãŸã‚µã‚¤ãƒˆï¼šhttps://www.gomlab.com/download/  
![random.JPG](attachment:random.JPG)

**ï¼œç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆï¼**  
![kousei.JPG](attachment:kousei.JPG)


## ç”»åƒãƒ‡ãƒ¼ã‚¿ã®åé›†ä½œæ¥­ï¼ˆå‚è€ƒå‹•ç”»ï¼‰
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åé›†ã®ãŸã‚ã€1æœ¬ã®ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ã‚’30åˆ†é–“ã€1å›ã«ã¤ãã€ç´„2åº¦ãšã¤ã®å›è»¢ã‚’ç´„500å›ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ãªãŒã‚‰ã€ãŠã‚ˆãï¼“å‘¨ã•ã›ã¾ã—ãŸã€‚ã“ã‚Œã‚’åˆè¨ˆ5æœ¬åˆ†ï¼ˆä½œæ¥­æ™‚é–“2æ™‚é–“30åˆ†ã€‚ä¼‘æ†©è¾¼ã§åŠæ—¥ï¼‰è¡Œã„ã¾ã—ãŸã€‚è¦‹ãŸç›®ã€åœ°å‘³ã§å˜èª¿ã«è¦‹ãˆã¾ã™ãŒã€å¾®å¦™ãªèª¿æ•´åŠ›ãŒå¿…è¦ã§ã€æ­£ç›´ã¨ã¦ã‚‚è¾›ã„ä½œæ¥­ã§ã—ãŸã€‚æœ€å¾Œã®æ–¹ã¯ã€è…±é˜ç‚ã«ãªã‚‹ã‹ã¨æ€ã†ãã‚‰ã„ã§ã—ãŸã€‚ï¼ˆå®Ÿéš›ã«ã¯ã€åœŸå°ã‚’ãƒ¢ãƒ¼ã‚¿ã§å›è»¢ã—ãªãŒã‚‰è‡ªå‹•ã§ã‚„ã‚‹ã“ã¨ã«ãªã‚‹ã‹ã¨æ€ã„ã¾ã™ãŒãƒ»ãƒ»ãƒ»ï¼‰


```python
import IPython.display
IPython.display.VimeoVideo('311607178')
```





        <iframe
            width="400"
            height="300"
            src="https://player.vimeo.com/video/311607178"
            frameborder="0"
            allowfullscreen
        ></iframe>
        



# å­¦ç¿’å†…å®¹
VGG16ã€MobileNetã€MobileNetã®3ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è»¢ç§»å­¦ç¿’ã™ã‚‹ã€‚  
â€»MobileNetã§å­¦ç¿’ã™ã‚‹å‰ã«ã€VGG16ã§ç²¾åº¦ãŒã§ã‚‹ã‹ç¢ºèªã—ãŸã€‚ 
â€»å…¥åŠ›ã®Shapeï¼ˆ224Ã—224ï¼‰ãŒå½±éŸ¿ã™ã‚‹ã‹ç¢ºèªã—ãŸã€‚

## è‹¦åŠ´ã—ãŸã¨ã“ã‚
ç²¾åº¦ã‚’100ï¼…ã«è¿‘ã¥ã‘ã‚‹ã¨ã“ã‚ã§ã™ã€‚ã€Œ99%å‡ºã¾ã—ãŸï¼ã€ã¯ä¸€è¦‹ç²¾åº¦ãŒå‡ºã¦ã„ã‚‹ã‚ˆã†ã§ã™ãŒã€ç„¡äººãƒ¬ã‚¸ã§è¨€ãˆã°100å•†å“ã‚ãŸã‚Š1å•†å“ã‚’èª¤æ¤œçŸ¥ã—ã¦ã—ã¾ã†ã¨ã„ã†ã¨ã‚“ã§ã‚‚ç„¡ã„ã‚·ã‚¹ãƒ†ãƒ ã«ãªã£ã¦ã—ã¾ã™ã€‚100ï¼…ã§ãªã‘ã‚Œã°ã„ã‘ãªã„ç„¡äººãƒ¬ã‚¸ã®é›£æ˜“åº¦ã®é«˜ã•ã‚’æ„Ÿã˜ã¾ã—ãŸã€‚ã©ã†ã—ã¦ã‚‚ç¢ºç‡çš„è¦ç´ ãŒç™ºç”Ÿã—ã¦ã—ã¾ã†ç”»åƒèªè­˜æŠ€è¡“ã‚’ç„¡äººãƒ¬ã‚¸ã«å±•é–‹ã—ã¦ã„ã‚‹ã§ã‚ã‚ã†AmazonGOã‚„JRæ±æ—¥æœ¬ã¯ã©ã®ã‚ˆã†ã«ã—ã¦å®Ÿè£…ã—ã¦ã„ã‚‹ã®ã‹ã¨ã¦ã‚‚æ°—ã«ãªã‚Šã¾ã™ã€‚

## å­¦ç¿’çµæœã¾ã¨ã‚
äºˆæƒ³é€šã‚ŠVGG16ãŒä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦ä¸€ç•ªã®ç²¾åº¦ãŒå‡ºã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã—ã‹ã—ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ã‚ºãƒ‘ã‚¤ã«ã¯å…¥ã‚‰ãªã„é›£ç‚¹ãŒã‚ã‚‹ã€‚å®¹é‡ãŒå°ã•ãã€æ€§èƒ½ã‚‚å‡ºã¦ã„ã‚‹MobileNetï¼ˆ224ï¼‰ãŒãƒ™ã‚¹ãƒˆã ã¨è¨€ãˆã‚‹ã€‚  

|ãƒ†ã‚¹ãƒˆ|VGG16(224)|MobileNet(224)|MobileNet(160)|MobileNetV2(224)|MobileNetV2(160)|
|:--|:--:|:--:|:--:|:--:|:--:|
|Test1ï¼ˆã‚­ãƒƒãƒãƒªï¼‰|1.0|0.9875|0.95625|0.99375|0.990625|
|Test2ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰|1.0|0.978125|0.878125|0.96875|0.875|
|h5ã®å®¹é‡|121MB|25MB|25MB|41MB|41MB|

## ãã‚Œãã‚Œã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ›²ç·š
### VGG16 
![VGG16.png](attachment:VGG16.png)

### MobileNetï¼ˆ224ï¼‰ 
![MobileNet224.png](attachment:MobileNet224.png)

### MobileNetï¼ˆ160ï¼‰ 
![MobileNet160.png](attachment:MobileNet160.png)

### MobileNetV2ï¼ˆ224ï¼‰
![MobileNetV2_224.png](attachment:MobileNetV2_224.png)

### MobileNetV2ï¼ˆ160ï¼‰
![MobileNetV2_160.png](attachment:MobileNetV2_160.png)

# ãƒ©ã‚ºãƒ™ãƒªãƒ¼ãƒ‘ã‚¤ã®å®Ÿè£…

ğŸ”·ãƒ©ã‚ºãƒ™ãƒªãƒ¼ãƒ‘ã‚¤ã§ã¯VGGç­‰ã®å¤§ãã„ãƒ¢ãƒ‡ãƒ«ã§ã¯å‹•ä½œã•ã›ã‚‹äº‹ãŒã§ããªã„ã€‚ãã®ãŸã‚ã€MobileNet ã§ãƒ¢ãƒ‡ãƒ«ä½œã‚Šã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ©ã‚ºãƒ™ãƒªãƒ¼ãƒ‘ã‚¤ã§å‹•ãã‚ˆã†ã«å®Ÿè£…ã‚’è¡Œã£ãŸã€‚  

ğŸ”·æ“ä½œãƒ•ãƒ­ãƒ¼ã¯ä»¥ä¸‹ã§ã™ã€‚  
â‘ åˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚º(å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰, éŸ³å£°ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–)   
â‘¡ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‹ã‚‰ã®å…¥åŠ›å¾…ã¡  
â‘¢ç”»åƒå–å¾—  
â‘£æ¨è«–  
 
 
## ãƒ©ã‚ºãƒ‘ã‚¤ã«è¼‰ã›ãŸã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹


```python
#!/usr/bin/env python
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import img_to_array
import pygame.mixer
import numpy as np
import picamera
from PIL import Image
from time import sleep

# ã‚«ãƒ¡ãƒ©ã®å–å¾—ç”»åƒä¿å­˜å…ˆ
photo_filename = '/tmp/data.jpg'

# ã‚«ãƒ¡ãƒ©ã‹ã‚‰ç”»åƒã‚’å–å¾—ã—ã€ä¿å­˜ã™ã‚‹
def shutter():
    photofile = open(photo_filename, 'wb')
    print(photofile)

    # pi camera ç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€ç”»åƒã‚’å–å¾—
    with picamera.PiCamera() as camera:
        camera.resolution = (300,400)
        camera.start_preview()
        sleep(1.000)
        camera.capture(photofile)

if __name__ == '__main__':
    # ãƒ¢ãƒ‡ãƒ«+é‡ã¿ã‚’èª­è¾¼ã¿
    self_model = load_model('MobileNet_auto_fine2.h5')
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–
    pygame.mixer.init()
    pygame.mixer.music.load("Cash_Register-Beep01-1.mp3")

    # æ­£è§£ãƒ©ãƒ™ãƒ«
    label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo', 'o-iocha', 'pocari-sweat']
    # å•†å“ä¾¡æ ¼
    money = {'cocacola-peach':110, 'ilohas':120, 'kuchidoke-momo':130, 'o-iocha':140, 'pocari-sweat':150}

    while True:
        money_sum = 0 
        key = input('å•†å“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯ã€ŒEnterã€ã‚’æŠ¼ã—ã¦ä¸‹ã•ã„')
        while True:
            # ç”»åƒã®å–å¾—
            shutter()

            # éŸ³å£°å†ç”Ÿ
            pygame.mixer.music.play(1)
            sleep(1)
            # å†ç”Ÿã®çµ‚äº†
            pygame.mixer.music.stop()

            # ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ç”¨ã«åŠ å·¥
            img = Image.open(photo_filename)
            img = img.resize((224, 224))
            img_array = img_to_array(img)
            img_array = img_array.astype('float32')/255.0
            img_array = img_array.reshape((1,224,224,3))
            
            # predict
            img_pred = self_model.predict(img_array)
            name = label[np.argmax(img_pred)]
            print(name)
            money_sum += money[name]
            print("å°è¨ˆ:{}å††".format(money_sum))
            key = input('ç¶šã‘ã¦å•†å“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯ã€Œy + Enterã€,ä¼šè¨ˆã™ã‚‹å ´åˆã¯ã€ŒEnterã€ã‚’æŠ¼ã—ã¦ä¸‹ã•ã„')
            if key != 'y':
                print("åˆè¨ˆ:{}å††".format(money_sum))
                break
```

# æ¤œè¨¼çµæœ
ã»ã¼æ­£è§£ã—ã¦ã„ã‚‹ã€‚ä»¥ä¸‹ã«ãƒ©ã‚ºãƒ‘ã‚¤ã§å–å¾—ã—ãŸç”»åƒã¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®è¡¨ç¤ºç”»åƒã‚’ç¤ºã™ã€‚

## ã‚³ãƒ¼ã‚½ãƒ¼ãƒ«ç”»é¢ 	
![Screenshot.png](attachment:Screenshot.png)

## ãƒ©ã‚ºãƒ‘ã‚¤ã®å–å¾—ç”»åƒ
![pic.JPG](attachment:pic.JPG)

## ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¦ã„ã‚‹ã¨ã“ã‚ã®è€ƒå¯Ÿ
ä»Šå›ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã©ã“ã‚’è¦‹ã¦ã„ã‚‹ã‹æ¤œè¨ã™ã¹ãã€å­¦ç¿’ã—ã¦ã„ãªã„ç‰©ã§æ¨è«–ã‚’è¡Œã£ãŸã€‚çµæœä»¥ä¸‹ã®å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¢ºèªã§ããŸã€‚<br>
- ãƒ©ãƒ™ãƒ«ã‚’å‰¥ãŒã—ãŸå ´åˆ<br>
ãƒšãƒƒãƒˆãƒœãƒˆãƒ«ã®å½¢ã§åˆ¤æ–­ã‚’ã—ã¦ãŠã‚Šã€ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€ã‚„ã€ŒãŠãƒ¼ã„ãŠèŒ¶ã€ãªã©ã®å½¢ãŒé•ã†ã‚‚ã®ã¯èªè­˜ãŒã§ããŸã€‚ã—ã‹ã—ã€ã€Œãã¡ã©ã‘ã€ã®å ´åˆã¯ã€ŒãŠãƒ¼ã„ãŠèŒ¶ã€ã¨èªè­˜ã—ãŸã€‚ã¾ãŸã€åŒã˜ãƒ¡ãƒ¼ã‚«ã®å•†å“ã§å½¢ãŒä¼¼ã¦ã„ã‚‹ã‚‚ã®ã¯äººé–“ã®ç›®ã‹ã‚‰è¦‹ã¦ã‚‚ä¸€ç•ªä¼¼ã¦ã„ã‚‹ã‚‚ã®ã‚’èªè­˜ã—ãŸã€‚<br>

- ãƒ©ãƒ™ãƒ«ã®ã¿ <br>
å…¨ã¦ã®ãƒ©ãƒ™ãƒ«ã§æ­£ã—ãèªè­˜ã™ã‚‹ã“ã¨ãŒã§ããŸã€‚ã¾ãŸã€ãƒ©ãƒ™ãƒ«ã®å½¢ã‚„ãƒ‡ã‚¶ã‚¤ãƒ³ãŒä¼¼ã¦ã„ã‚‹ã‚‚ã®ã¯ã‚„ã¯ã‚Šã€ä¸€ç•ªä¼¼ã¦ã„ã‚‹ã¨èªè­˜ã—ãŸã€‚<br>

- ãƒ‡ã‚¶ã‚¤ãƒ³<br>
ã€Œãã¡ã©ã‘ã€ã¨ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€ã«ã€Œæ¡ƒã€ã®ãƒ‡ã‚¶ã‚¤ãƒ³ãŒå…¥ã£ã¦ã„ã‚‹ã€‚ã“ã®æ¡ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã¯ä¸¸ã«è¿‘ã„ãƒ‡ã‚¶ã‚¤ãƒ³ã¨ãªã£ã¦ã„ã‚‹ã€‚ãã®ãŸã‚ã€ä¸¸ã„ãƒ‡ã‚¶ã‚¤ãƒ³ãŒå…¥ã£ã¦ã„ã‚‹å†Šå­ã‚’èªè­˜ã•ã›ãŸã¨ã“ã‚ã€Œãã¡ã©ã‘ã€ã‚„ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€ã¨ãªã£ãŸã€‚çµæœãŒç•°ãªã£ãŸã®ã¯å†Šå­ã‚’ç½®ã„ãŸå‘ãã‚„è§’åº¦ã«ã‚ˆã£ã¦ç•°ãªã£ãŸã€‚<br>
ã¾ãŸã€ã‚¬ãƒ ã®ãƒœãƒˆãƒ«ã§ã‚‚è©¦ã—ãŸã€‚ã‚¬ãƒ ã®ãƒœãƒˆãƒ«ã‚’ç«‹ã¦ãŸçŠ¶æ…‹ã§ã€ŒãŠãƒ¼ã„ãŠèŒ¶ã€ã¨èªè­˜ã—ãŸã€‚ãƒœãƒˆãƒ«ã®ãƒ‡ã‚¶ã‚¤ãƒ³ãŒç·‘ã§ã‚ã‚Šã€ãƒœãƒˆãƒ«ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«å‡¹å‡¸ãŒãªã„ãŸã‚ã ã¨æ€ã‚ã‚Œã‚‹ã€‚ä»Šåº¦ã¯ã€ãƒœãƒˆãƒ«ã‚’æ¨ªã«å¯ã‹ã—è“‹ã®æ­£é¢ã‚’ã‚«ãƒ¡ãƒ©ã«å‘ã‘ã‚‹ã¨ã€Œãã¡ã©ã‘ã€ã¨èªè­˜ã—ãŸã€‚

- è‰²<br>
å…¨ã¦ã®è‰²ã§ã¯è©¦ã—ã¦ã„ãªã„ãŒã€é’ã€ãƒ”ãƒ³ã‚¯ã‚’è©¦ã—ãŸã¨ã“ã‚ã€é’ã¯ã€Œãƒã‚«ãƒªã‚¹ã‚¨ãƒƒãƒˆã€ã¨èªè­˜ã—ã€ãƒ”ãƒ³ã‚¯ã¯ã€Œãã¡ã©ã‘ã€ã‚„ã€Œã‚³ã‚«ã‚³ãƒ¼ãƒ©ãƒ”ãƒ¼ãƒã€ã¨èªè­˜ã—ãŸã€‚<br>

ä»¥ä¸Šã‹ã‚‰çµæœã‹ã‚‰ã€ãƒ¢ãƒ‡ãƒ«ã¯ãƒœãƒˆãƒ«ã®å½¢ã€è‰²ã€ãƒ©ãƒ™ãƒ«ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’èªè­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ããŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€åŒã˜ãƒ¡ãƒ¼ã‚«ã®å•†å“ã§ãƒ•ãƒ¬ãƒ¼ãƒãƒ¼ãŒç•°ãªã‚‹ã‚ˆã†ãªå•†å“ã®å ´åˆã¯ãƒœãƒˆãƒ«ã®å½¢ã€ãƒ‡ã‚¶ã‚¤ãƒ³ãŒä¼¼ã¦ã„ã‚‹ãŸã‚ã€èª¤èªè­˜ã—ã‚„ã™ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ãƒ†ã‚¹ãƒˆã™ã‚‹éš›ã«ã¯ã€é¡ä¼¼å“åŒå£«ãŒçµæœã‚’æ¯”ã¹ã€èª¤èªè­˜ã™ã‚‹å‚¾å‘ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

# ã‚„ã‚Šæ®‹ã—ãŸã“ã¨ã‚„ä»Šå¾Œã«å‘ã‘ã¦
ãƒ»MobileNetã¨VGG16ã§ãªãœç²¾åº¦ãŒç•°ãªã‚‹ã®ã‹ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®é•ã„ãªã©ã®åŸå› ã‚’ã‚‚ã†å°‘ã—èª¿æŸ»ã—ãŸã„ã€‚  
ãƒ»æ–°ãŸã«å•†å“ãŒè¿½åŠ ã•ã‚ŒãŸæ™‚ã®å¯¾å¿œã¨ã—ã¦ã€ãƒãƒƒãƒå­¦ç¿’ï¼ˆä¸€æ‹¬å­¦ç¿’ï¼‰ã§ã¯ãªãã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ï¼ˆé€æ¬¡å­¦ç¿’ï¼‰ã§ã‚ã‚Œã°ã©ã®ã‚ˆã†ã«å®Ÿè£…ã™ã‚‹ã¹ãã‹æ¤œè¨ã™ã‚‹ã€‚  

# ----------------ä»¥ä¸‹ã¯å­¦ç¿’è¨˜éŒ²----------------

# å­¦ç¿’çµæœã‚µãƒãƒª

## VGG16ï¼ˆ224Ã—224ï¼‰
**Log-loss (cost function):**  
training   (min:    0.005, max:    1.397, cur:    0.005)  
validation (min:    0.001, max:    0.702, cur:    0.001)  

**Accuracy:**  
training   (min:    0.436, max:    1.000, cur:    1.000)  
validation (min:    0.850, max:    1.000, cur:    1.000) 


**Predictï¼ˆtest1ï¼‰**  
 test loss: 3.881290031131357e-05  
 test_acc: 1.0  

**Predictï¼ˆtest2ï¼‰**  
 test loss: 0.0034616337517945793  
 test_acc: 1.0   
 
 ## MobileNetï¼ˆ224Ã—224ï¼‰
**Log-loss (cost function):**  
training   (min:    0.054, max:    1.645, cur:    0.108)  
validation (min:    0.032, max:    1.358, cur:    0.083)  

**Accuracy:**  
training   (min:    0.350, max:    0.983, cur:    0.960)  
validation (min:    0.375, max:    1.000, cur:    0.984)  

**Predictï¼ˆtest1ï¼‰**   
 test loss: 0.06109768375754356  
 test_acc: 0.9875  

**Predictï¼ˆtest2ï¼‰**   
 test loss: 0.06645064856857061  
 test_acc: 0.978125  
 
 ## MobileNetï¼ˆ160Ã—160ï¼‰
**Log-loss (cost function):**  
training   (min:    0.088, max:    1.850, cur:    0.119)  
validation (min:    0.131, max:    1.329, cur:    0.404)  

**Accuracy:**  
training   (min:    0.271, max:    0.975, cur:    0.960)  
validation (min:    0.487, max:    0.969, cur:    0.844)  

**Predictï¼ˆtest1ï¼‰**   
 test loss: 0.1379891701042652   
 test_acc: 0.95625   

**Predictï¼ˆtest2ï¼‰**   
 test loss: 0.3826994106173515   
 test_acc: 0.878125   
 
 ## MobileNetV2ï¼ˆ224Ã—224ï¼‰
**Log-loss (cost function):**  
training   (min:    0.000, max:    1.368, cur:    0.004)  
validation (min:    0.028, max:    1.159, cur:    0.042)  

**Accuracy:**  
training   (min:    0.460, max:    1.000, cur:    0.998)  
validation (min:    0.619, max:    0.997, cur:    0.994)  

**Predictï¼ˆtest1ï¼‰**  
 test loss: 0.0463521271944046  
 test_acc: 0.99375  

**Predictï¼ˆtest2ï¼‰**   
 test loss: 0.08764868583530187  
 test_acc: 0.96875  

## MobileNetV2ï¼ˆ160Ã—160ï¼‰
**Log-loss (cost function):**  
training   (min:    0.001, max:    1.370, cur:    0.001)   
validation (min:    0.035, max:    1.086, cur:    0.385)   

**Accuracy:**  
training   (min:    0.435, max:    1.000, cur:    1.000)   
validation (min:    0.631, max:    0.994, cur:    0.903)   

**Predictï¼ˆtest1ï¼‰**  
 test loss: 0.0448226616717875   
 test_acc: 0.990625   

**Predictï¼ˆtest2ï¼‰**  
 test loss: 0.4968989446759224   
 test_acc: 0.875

# VGG16ï¼ˆ224Ã—224ï¼‰


```python
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Input,Dropout
from keras.applications.mobilenet import MobileNet
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import CSVLogger,EarlyStopping
from livelossplot.keras import PlotLossesCallback
%matplotlib inline

n_categories=5
batch_size=32
train_dir = './images/train'
validation_dir = './images/val'
file_name='VGG16_shape224'

base_model=VGG16(input_shape=(224,224,3),
                 weights='imagenet',
                 include_top=False,)

#add new layers instead of FC networks
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
x=Dense(1024,activation='relu')(x)
prediction=Dense(n_categories,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=prediction)

#fix weights before MobileNet
for layer in base_model.layers[:15]:
    layer.trainable=False

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#save model
train_datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

hist=model.fit_generator(train_generator,
                         steps_per_epoch=20,
                         epochs=15,
                         verbose=1,
                         validation_data=validation_generator,
                         validation_steps=10,
                         callbacks=[EarlyStopping(patience=10),PlotLossesCallback()])

#save weights
model.save(file_name+'.h5')
```


![png](output_14_0.png)


    Log-loss (cost function):
    training   (min:    0.005, max:    1.397, cur:    0.005)
    validation (min:    0.001, max:    0.702, cur:    0.001)
    
    Accuracy:
    training   (min:    0.436, max:    1.000, cur:    1.000)
    validation (min:    0.850, max:    1.000, cur:    1.000)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='VGG16_shape224'
test_dir = './images/test'
display_dir = './images/display'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 435 images belonging to 5 classes.
    
     test loss: 3.881290031131357e-05
    
     test_acc: 1.0
    img_pred     :     0     [[ 0  0  0 99  0]]
    img_pred     :     1     [[  0   0 100   0   0]]
    img_pred     :     2     [[99  0  0  0  0]]
    img_pred     :     3     [[99  0  0  0  0]]
    img_pred     :     4     [[ 0  0 99  0  0]]
    img_pred     :     5     [[ 0  0 99  0  0]]
    img_pred     :     6     [[ 0  0  0  0 99]]
    img_pred     :     7     [[ 0 99  0  0  0]]
    img_pred     :     8     [[99  0  0  0  0]]
    img_pred     :     9     [[ 0 99  0  0  0]]
    img_pred     :     10     [[  0   0   0 100   0]]
    img_pred     :     11     [[ 0  0 99  0  0]]
    img_pred     :     12     [[ 0 99  0  0  0]]
    img_pred     :     13     [[ 0  0 99  0  0]]
    img_pred     :     14     [[99  0  0  0  0]]
    img_pred     :     15     [[  0   0 100   0   0]]
    img_pred     :     16     [[  0   0 100   0   0]]
    img_pred     :     17     [[ 0  0  0  0 99]]
    img_pred     :     18     [[ 0  0 99  0  0]]
    img_pred     :     19     [[ 0  0 99  0  0]]
    img_pred     :     20     [[ 0 99  0  0  0]]
    img_pred     :     21     [[ 0  0  0 99  0]]
    img_pred     :     22     [[ 0  0  0  0 99]]
    img_pred     :     23     [[ 0  0  0 99  0]]
    img_pred     :     24     [[99  0  0  0  0]]



![png](output_15_1.png)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD,Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='VGG16_shape224'
test_dir = './images/test2'
display_dir = './images/display2'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 340 images belonging to 5 classes.
    
     test loss: 0.0034616337517945793
    
     test_acc: 1.0
    img_pred     :     0     [[ 0 99  0  0  0]]
    img_pred     :     1     [[ 0  0 99  0  0]]
    img_pred     :     2     [[  0   0   0 100   0]]
    img_pred     :     3     [[99  0  0  0  0]]
    img_pred     :     4     [[ 0  0  0  0 99]]
    img_pred     :     5     [[  0   0   0 100   0]]
    img_pred     :     6     [[100   0   0   0   0]]
    img_pred     :     7     [[99  0  0  0  0]]
    img_pred     :     8     [[  0   0   0 100   0]]
    img_pred     :     9     [[99  0  0  0  0]]
    img_pred     :     10     [[  0   0   0   0 100]]
    img_pred     :     11     [[  0   0   0 100   0]]
    img_pred     :     12     [[  0   0   0 100   0]]
    img_pred     :     13     [[ 0 99  0  0  0]]
    img_pred     :     14     [[ 0  0 99  0  0]]
    img_pred     :     15     [[  0   0 100   0   0]]
    img_pred     :     16     [[ 0  0  0  0 99]]
    img_pred     :     17     [[  0   0   0 100   0]]
    img_pred     :     18     [[  0   0   0 100   0]]
    img_pred     :     19     [[  0 100   0   0   0]]
    img_pred     :     20     [[  0   0 100   0   0]]
    img_pred     :     21     [[  0   0   0 100   0]]
    img_pred     :     22     [[ 0  0 99  0  0]]
    img_pred     :     23     [[  0   0   0 100   0]]
    img_pred     :     24     [[  0   0   0 100   0]]



![png](output_16_1.png)


# MobileNetV1ï¼ˆ224Ã—224ï¼‰


```python
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Input,Dropout
from keras.applications.mobilenet import MobileNet
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import CSVLogger,EarlyStopping
from livelossplot.keras import PlotLossesCallback
%matplotlib inline

n_categories=5
batch_size=32
train_dir = './images/train'
validation_dir = './images/val'
file_name='MobileNet_shape224'

base_model=MobileNet(input_shape=(224,224,3),
                     weights='imagenet',
                     include_top=False
                     #dropout=0.1
                    )

#add new layers instead of FC networks
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
x=Dense(1024,activation='relu')(x)
prediction=Dense(n_categories,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=prediction)

#fix weights before MobileNet
for layer in base_model.layers[:85]:
    layer.trainable=False

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#save model
train_datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    horizontal_flip=True)

validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

hist=model.fit_generator(train_generator,
                         steps_per_epoch=15,
                         epochs=100,
                         verbose=1,
                         validation_data=validation_generator,
                         validation_steps=10,
                         #callbacks=[EarlyStopping(patience=20),PlotLossesCallback()]
                         callbacks=[PlotLossesCallback()]
                        )

#save weights
model.save(file_name+'.h5')
```


![png](output_18_0.png)


    Log-loss (cost function):
    training   (min:    0.054, max:    1.645, cur:    0.108)
    validation (min:    0.032, max:    1.358, cur:    0.083)
    
    Accuracy:
    training   (min:    0.350, max:    0.983, cur:    0.960)
    validation (min:    0.375, max:    1.000, cur:    0.984)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNet_shape224'
test_dir = './images/test'
display_dir = './images/display'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 435 images belonging to 5 classes.
    
     test loss: 0.06109768375754356
    
     test_acc: 0.9875
    img_pred     :     0     [[ 0 77  1  0 20]]
    img_pred     :     1     [[ 0  0 99  0  0]]
    img_pred     :     2     [[ 0  0 99  0  0]]
    img_pred     :     3     [[ 0 86  0  1 11]]
    img_pred     :     4     [[ 0  0  5 94  0]]
    img_pred     :     5     [[ 0  0 99  0  0]]
    img_pred     :     6     [[ 0  0 99  0  0]]
    img_pred     :     7     [[92  0  7  0  0]]
    img_pred     :     8     [[97  0  2  0  0]]
    img_pred     :     9     [[ 0  0  0 99  0]]
    img_pred     :     10     [[59  0 38  0  1]]
    img_pred     :     11     [[ 0  0 99  0  0]]
    img_pred     :     12     [[ 0  0  0  0 99]]
    img_pred     :     13     [[99  0  0  0  0]]
    img_pred     :     14     [[57  0 41  0  0]]
    img_pred     :     15     [[ 0 87  0  0 10]]
    img_pred     :     16     [[ 0  0  0 99  0]]
    img_pred     :     17     [[ 0 63  6  1 28]]
    img_pred     :     18     [[ 0 96  0  0  3]]
    img_pred     :     19     [[ 0  0  0  0 99]]
    img_pred     :     20     [[ 0  0  0 99  0]]
    img_pred     :     21     [[ 0  0  0 99  0]]
    img_pred     :     22     [[ 0  0  0 99  0]]
    img_pred     :     23     [[ 0 86  1  3  7]]
    img_pred     :     24     [[ 0  0  0 99  0]]



![png](output_19_1.png)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNet_shape224'
test_dir = './images/test2'
display_dir = './images/display2'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 340 images belonging to 5 classes.
    
     test loss: 0.06645064856857061
    
     test_acc: 0.978125
    img_pred     :     0     [[ 0  0 99  0  0]]
    img_pred     :     1     [[ 0 99  0  0  0]]
    img_pred     :     2     [[ 0  0  1 98  0]]
    img_pred     :     3     [[ 0  0  2 97  0]]
    img_pred     :     4     [[95  0  0  0  2]]
    img_pred     :     5     [[ 0  0 99  0  0]]
    img_pred     :     6     [[ 0  0 99  0  0]]
    img_pred     :     7     [[95  0  3  0  0]]
    img_pred     :     8     [[ 0  0  0  0 99]]
    img_pred     :     9     [[ 0  0 99  0  0]]
    img_pred     :     10     [[ 0  0  0 99  0]]
    img_pred     :     11     [[99  0  0  0  0]]
    img_pred     :     12     [[ 0  0  0 99  0]]
    img_pred     :     13     [[ 0  0 99  0  0]]
    img_pred     :     14     [[ 0  0 99  0  0]]
    img_pred     :     15     [[ 0  1  0 95  1]]
    img_pred     :     16     [[ 0  0 99  0  0]]
    img_pred     :     17     [[ 0 99  0  0  0]]
    img_pred     :     18     [[40  0 44  0 14]]
    img_pred     :     19     [[ 0 99  0  0  0]]
    img_pred     :     20     [[ 0 99  0  0  0]]
    img_pred     :     21     [[95  0  0  0  4]]
    img_pred     :     22     [[ 0  0  0 99  0]]
    img_pred     :     23     [[99  0  0  0  0]]
    img_pred     :     24     [[ 0  0  0  0 99]]



![png](output_20_1.png)


# MobileNetï¼ˆ160Ã—160ï¼‰


```python
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Input,Dropout
from keras.applications.mobilenet import MobileNet
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import CSVLogger,EarlyStopping
from livelossplot.keras import PlotLossesCallback
%matplotlib inline

n_categories=5
batch_size=32
train_dir = './images/train'
validation_dir = './images/val'
file_name='MobileNet_shape160'

base_model=MobileNet(input_shape=(160,160,3),
                     weights='imagenet',
                     include_top=False
                     #dropout=0.1
                    )

#add new layers instead of FC networks
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
x=Dense(1024,activation='relu')(x)
prediction=Dense(n_categories,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=prediction)

#fix weights before MobileNet
for layer in base_model.layers[:85]:
    layer.trainable=False

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#save model
train_datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    horizontal_flip=True)

validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

hist=model.fit_generator(train_generator,
                         steps_per_epoch=15,
                         epochs=100,
                         verbose=1,
                         validation_data=validation_generator,
                         validation_steps=10,
                         #callbacks=[EarlyStopping(patience=20),PlotLossesCallback()]
                         callbacks=[PlotLossesCallback()]
                        )

#save weights
model.save(file_name+'.h5')
```


![png](output_22_0.png)


    Log-loss (cost function):
    training   (min:    0.088, max:    1.850, cur:    0.119)
    validation (min:    0.131, max:    1.329, cur:    0.404)
    
    Accuracy:
    training   (min:    0.271, max:    0.975, cur:    0.960)
    validation (min:    0.487, max:    0.969, cur:    0.844)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNet_shape160'
test_dir = './images/test'
display_dir = './images/display'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(160,160))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,160,160,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 435 images belonging to 5 classes.
    
     test loss: 0.1379891701042652
    
     test_acc: 0.95625
    img_pred     :     0     [[ 0  0  0  0 99]]
    img_pred     :     1     [[ 0  0  0 99  0]]
    img_pred     :     2     [[ 0 91  0  2  5]]
    img_pred     :     3     [[ 1 88  4  2  3]]
    img_pred     :     4     [[ 0  0 99  0  0]]
    img_pred     :     5     [[ 0  0 98  1  0]]
    img_pred     :     6     [[ 0  0  0  0 99]]
    img_pred     :     7     [[ 0  0  0 99  0]]
    img_pred     :     8     [[ 0  0  0  0 99]]
    img_pred     :     9     [[ 0  0 99  0  0]]
    img_pred     :     10     [[ 0  0  0 99  0]]
    img_pred     :     11     [[96  0  2  0  0]]
    img_pred     :     12     [[86  0 11  2  0]]
    img_pred     :     13     [[ 1 79  1  1 15]]
    img_pred     :     14     [[ 0  0  0 99  0]]
    img_pred     :     15     [[ 0  0 99  0  0]]
    img_pred     :     16     [[ 0  0 99  0  0]]
    img_pred     :     17     [[ 0  0  0 99  0]]
    img_pred     :     18     [[ 0 95  0  0  3]]
    img_pred     :     19     [[ 0  0  0 99  0]]
    img_pred     :     20     [[ 0  0 99  0  0]]
    img_pred     :     21     [[ 0  0  0  0 99]]
    img_pred     :     22     [[ 0  0  0  0 99]]
    img_pred     :     23     [[56  0 38  1  2]]
    img_pred     :     24     [[ 0  0  0 99  0]]



![png](output_23_1.png)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNet_shape160'
test_dir = './images/test2'
display_dir = './images/display2'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(160,160))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,160,160,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 340 images belonging to 5 classes.
    
     test loss: 0.3826994106173515
    
     test_acc: 0.878125
    img_pred     :     0     [[24  0 37  1 36]]
    img_pred     :     1     [[ 0  0  0  0 99]]
    img_pred     :     2     [[ 0  0 99  0  0]]
    img_pred     :     3     [[ 0  0  8 91  0]]
    img_pred     :     4     [[ 0 81  0  5 12]]
    img_pred     :     5     [[ 8  0  5  3 83]]
    img_pred     :     6     [[30  0 68  0  0]]
    img_pred     :     7     [[ 0 97  1  0  0]]
    img_pred     :     8     [[ 0  0  0  0 99]]
    img_pred     :     9     [[ 0  0  0  0 99]]
    img_pred     :     10     [[ 0  0  0 99  0]]
    img_pred     :     11     [[ 0  0  0  0 99]]
    img_pred     :     12     [[20  0 78  0  1]]
    img_pred     :     13     [[ 0  0  0  0 99]]
    img_pred     :     14     [[ 0 90  0  0  9]]
    img_pred     :     15     [[ 0 88  0  2  8]]
    img_pred     :     16     [[ 0  0  5 94  0]]
    img_pred     :     17     [[ 0  0 99  0  0]]
    img_pred     :     18     [[ 0  0  0  0 99]]
    img_pred     :     19     [[ 0 96  0  0  3]]
    img_pred     :     20     [[ 1  0 59  0 38]]
    img_pred     :     21     [[ 0  0  0  0 99]]
    img_pred     :     22     [[ 0  0  0  0 99]]
    img_pred     :     23     [[ 0  0 99  0  0]]
    img_pred     :     24     [[ 0  0  0  0 99]]



![png](output_24_1.png)


# MobileNetV2ï¼ˆ224Ã—224ï¼‰


```python
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Input,Dropout
from keras.applications.mobilenet import MobileNet
from keras.applications.mobilenetv2 import MobileNetV2
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import CSVLogger,EarlyStopping
from livelossplot.keras import PlotLossesCallback
%matplotlib inline

n_categories=5
batch_size=32
train_dir = './images/train'
validation_dir = './images/val'
file_name='MobileNetV2_shape224'

base_model=MobileNetV2(input_shape=(224,224,3),
                       weights='imagenet',
                       include_top=False)

#add new layers instead of FC networks
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
x=Dense(1024,activation='relu')(x)
prediction=Dense(n_categories,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=prediction)

#fix weights before MobileNet
for layer in base_model.layers[:85]:
    layer.trainable=False

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#save model
train_datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    horizontal_flip=True)

validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

hist=model.fit_generator(train_generator,
                         steps_per_epoch=15,
                         epochs=100,
                         verbose=1,
                         validation_data=validation_generator,
                         validation_steps=10,
                         #callbacks=[EarlyStopping(patience=2),PlotLossesCallback()]
                         callbacks=[PlotLossesCallback()]
                        )

#save weights
model.save(file_name+'.h5')
```


![png](output_26_0.png)


    Log-loss (cost function):
    training   (min:    0.000, max:    1.368, cur:    0.004)
    validation (min:    0.028, max:    1.159, cur:    0.042)
    
    Accuracy:
    training   (min:    0.460, max:    1.000, cur:    0.998)
    validation (min:    0.619, max:    0.997, cur:    0.994)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD,Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNetV2_shape224'
test_dir = './images/test'
display_dir = './images/display'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 435 images belonging to 5 classes.
    
     test loss: 0.0463521271944046
    
     test_acc: 0.99375
    img_pred     :     0     [[ 0  0  0 99  0]]
    img_pred     :     1     [[ 1  0 96  2  0]]
    img_pred     :     2     [[ 0  0 99  0  0]]
    img_pred     :     3     [[ 0 98  0  1  0]]
    img_pred     :     4     [[ 0  0 99  0  0]]
    img_pred     :     5     [[ 0  0  0  0 99]]
    img_pred     :     6     [[ 0 94  0  5  0]]
    img_pred     :     7     [[ 0  0  0 99  0]]
    img_pred     :     8     [[ 0 92  0  7  0]]
    img_pred     :     9     [[99  0  0  0  0]]
    img_pred     :     10     [[ 0  0  0  0 99]]
    img_pred     :     11     [[99  0  0  0  0]]
    img_pred     :     12     [[99  0  0  0  0]]
    img_pred     :     13     [[ 0  0  0 99  0]]
    img_pred     :     14     [[99  0  0  0  0]]
    img_pred     :     15     [[ 0  0  0  0 98]]
    img_pred     :     16     [[ 0 90  0  9  0]]
    img_pred     :     17     [[ 0  0  0 99  0]]
    img_pred     :     18     [[ 0  0  0  0 98]]
    img_pred     :     19     [[ 0 98  0  1  0]]
    img_pred     :     20     [[ 0  0  0  0 99]]
    img_pred     :     21     [[ 0  0  0  0 99]]
    img_pred     :     22     [[ 0  0 99  0  0]]
    img_pred     :     23     [[99  0  0  0  0]]
    img_pred     :     24     [[99  0  0  0  0]]



![png](output_27_1.png)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNetV2_shape224'
test_dir = './images/test2'
display_dir = './images/display2'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(224,224))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,224,224,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 340 images belonging to 5 classes.
    
     test loss: 0.08764868583530187
    
     test_acc: 0.96875
    img_pred     :     0     [[  0   0   0 100   0]]
    img_pred     :     1     [[89  0  1  0  8]]
    img_pred     :     2     [[ 0  0  0  0 99]]
    img_pred     :     3     [[ 0  0 99  0  0]]
    img_pred     :     4     [[ 0  0  0 99  0]]
    img_pred     :     5     [[ 0  0  0 99  0]]
    img_pred     :     6     [[81  0 17  0  0]]
    img_pred     :     7     [[  0   0   0 100   0]]
    img_pred     :     8     [[ 0  0  0  0 99]]
    img_pred     :     9     [[ 0  0 99  0  0]]
    img_pred     :     10     [[ 0  0  0  0 99]]
    img_pred     :     11     [[ 0  0 99  0  0]]
    img_pred     :     12     [[ 0 99  0  0  0]]
    img_pred     :     13     [[  0   0   0 100   0]]
    img_pred     :     14     [[ 0 99  0  0  0]]
    img_pred     :     15     [[ 0 99  0  0  0]]
    img_pred     :     16     [[ 0  0 99  0  0]]
    img_pred     :     17     [[ 0 99  0  0  0]]
    img_pred     :     18     [[ 0  0 12  0 86]]
    img_pred     :     19     [[ 0  0  0  0 99]]
    img_pred     :     20     [[ 0 99  0  0  0]]
    img_pred     :     21     [[ 0  0  0  0 99]]
    img_pred     :     22     [[  0 100   0   0   0]]
    img_pred     :     23     [[99  0  0  0  0]]
    img_pred     :     24     [[ 0  0  0 99  0]]



![png](output_28_1.png)


# MobileNetV2ï¼ˆ160Ã—160ï¼‰


```python
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D,Input,Dropout
from keras.applications.mobilenet import MobileNet
from keras.applications.mobilenetv2 import MobileNetV2
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import CSVLogger,EarlyStopping
from livelossplot.keras import PlotLossesCallback
%matplotlib inline

n_categories=5
batch_size=32
train_dir = './images/train'
validation_dir = './images/val'
file_name='MobileNetV2_shape160'

base_model=MobileNetV2(input_shape=(160,160,3),
                       weights='imagenet',
                       include_top=False)

#add new layers instead of FC networks
x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dropout(0.5)(x)
x=Dense(1024,activation='relu')(x)
prediction=Dense(n_categories,activation='softmax')(x)
model=Model(inputs=base_model.input,outputs=prediction)

#fix weights before MobileNet
for layer in base_model.layers[:85]:
    layer.trainable=False

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

#save model
train_datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    horizontal_flip=True)

validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

validation_generator=validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

hist=model.fit_generator(train_generator,
                         steps_per_epoch=15,
                         epochs=100,
                         verbose=1,
                         validation_data=validation_generator,
                         validation_steps=10,
                         #callbacks=[EarlyStopping(patience=2),PlotLossesCallback()]
                         callbacks=[PlotLossesCallback()]
                        )

#save weights
model.save(file_name+'.h5')
```


![png](output_30_0.png)


    Log-loss (cost function):
    training   (min:    0.001, max:    1.370, cur:    0.001)
    validation (min:    0.035, max:    1.086, cur:    0.385)
    
    Accuracy:
    training   (min:    0.435, max:    1.000, cur:    1.000)
    validation (min:    0.631, max:    0.994, cur:    0.903)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNetV2_shape160'
test_dir = './images/test'
display_dir = './images/display'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(160,160))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,160,160,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 435 images belonging to 5 classes.
    
     test loss: 0.0448226616717875
    
     test_acc: 0.990625
    img_pred     :     0     [[ 0 99  0  0  0]]
    img_pred     :     1     [[ 0 99  0  0  0]]
    img_pred     :     2     [[ 0  0 99  0  0]]
    img_pred     :     3     [[ 0  0  0 99  0]]
    img_pred     :     4     [[ 0  0  0  0 99]]
    img_pred     :     5     [[ 0  0  0  0 99]]
    img_pred     :     6     [[67  0  5  4 21]]
    img_pred     :     7     [[ 0 99  0  0  0]]
    img_pred     :     8     [[ 0  0  0 99  0]]
    img_pred     :     9     [[ 0 99  0  0  0]]
    img_pred     :     10     [[ 0  0 99  0  0]]
    img_pred     :     11     [[87  0  1  1  9]]
    img_pred     :     12     [[ 0  0  0  0 99]]
    img_pred     :     13     [[ 0 99  0  0  0]]
    img_pred     :     14     [[ 0  0  0 99  0]]
    img_pred     :     15     [[ 0  0 99  0  0]]
    img_pred     :     16     [[ 0  0  0  0 99]]
    img_pred     :     17     [[ 0 99  0  0  0]]
    img_pred     :     18     [[ 0  0  0  0 99]]
    img_pred     :     19     [[ 0  0  0  0 99]]
    img_pred     :     20     [[76  0  3  0 18]]
    img_pred     :     21     [[ 0  0  0 99  0]]
    img_pred     :     22     [[ 0  0  0  0 99]]
    img_pred     :     23     [[ 0  0  0 99  0]]
    img_pred     :     24     [[ 0  0 99  0  0]]



![png](output_31_1.png)



```python
import matplotlib.pyplot as plt
import numpy as np
import os,random
from keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.models import load_model
%matplotlib inline

batch_size=32
file_name='MobileNetV2_shape160'
test_dir = './images/test2'
display_dir = './images/display2'
label = ['cocacola-peach', 'ilohas', 'kuchidoke-momo','o-iocha','pocari-sweat']

#load model and weights
model = load_model(file_name+'.h5')

model.compile(optimizer=Adam(lr=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

#data generate
test_datagen=ImageDataGenerator(rescale=1.0/255)

test_generator=test_datagen.flow_from_directory(
    test_dir,
    target_size=(160,160),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

#evaluate model
score = model.evaluate_generator(test_generator, steps=10)
print('\n test loss:',score[0])
print('\n test_acc:',score[1])

#predict model and display images
files=os.listdir(display_dir)
img=random.sample(files,25)

plt.figure(figsize=(17,17))
for i in range(25):
    temp_img=load_img(os.path.join(display_dir,img[i]),target_size=(160,160))
    plt.subplot(5,5,i+1)
    plt.imshow(temp_img)
    #Images normalization
    temp_img_array=img_to_array(temp_img)
    temp_img_array=temp_img_array.astype('float32')/255.0
    temp_img_array=temp_img_array.reshape((1,160,160,3))
    #predict image
    img_pred=model.predict(temp_img_array)
    print('img_pred     :    ', i,'   ',(img_pred*100).astype(np.int))
    plt.title(str(i)+' : '+label[np.argmax(img_pred)])
    #eliminate xticks,yticks
    plt.xticks([]),plt.yticks([])

plt.show()
```

    Found 340 images belonging to 5 classes.
    
     test loss: 0.4968989446759224
    
     test_acc: 0.875
    img_pred     :     0     [[ 0  0  0 99  0]]
    img_pred     :     1     [[51 21 22  1  2]]
    img_pred     :     2     [[ 0  0  0 99  0]]
    img_pred     :     3     [[ 0  1  0  0 98]]
    img_pred     :     4     [[ 0 92  5  0  1]]
    img_pred     :     5     [[ 0  0  0 99  0]]
    img_pred     :     6     [[ 0  0 99  0  0]]
    img_pred     :     7     [[ 0 99  0  0  0]]
    img_pred     :     8     [[ 0  0  0 99  0]]
    img_pred     :     9     [[ 0  1  0 98  0]]
    img_pred     :     10     [[ 0  0  0 99  0]]
    img_pred     :     11     [[ 0  1  1  0 97]]
    img_pred     :     12     [[ 0  0  0 99  0]]
    img_pred     :     13     [[ 0  0 99  0  0]]
    img_pred     :     14     [[ 0  0  0 99  0]]
    img_pred     :     15     [[ 0 99  0  0  0]]
    img_pred     :     16     [[ 0  0 99  0  0]]
    img_pred     :     17     [[ 0  0  0 99  0]]
    img_pred     :     18     [[ 0  1  0  0 98]]
    img_pred     :     19     [[ 0 99  0  0  0]]
    img_pred     :     20     [[ 0 99  0  0  0]]
    img_pred     :     21     [[58  0  3  0 37]]
    img_pred     :     22     [[ 0  4  0 94  0]]
    img_pred     :     23     [[ 0  0 99  0  0]]
    img_pred     :     24     [[99  0  0  0  0]]



![png](output_32_1.png)

